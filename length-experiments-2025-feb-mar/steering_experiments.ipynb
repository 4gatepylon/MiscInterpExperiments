{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import json\n",
    "from contextlib import contextmanager\n",
    "import contextlib\n",
    "import io\n",
    "from copy import deepcopy\n",
    "from torch.utils.hooks import RemovableHandle\n",
    "from jinja2 import Template\n",
    "import pydantic\n",
    "import os\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from datasets import concatenate_datasets\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from safetensors.torch import save_file as safetensors_save_file\n",
    "from safetensors.torch import load_file as safetensors_load_file\n",
    "import random\n",
    "from datasets import load_dataset, Dataset, DatasetDict, Features, Value\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM\n",
    "import numpy as np\n",
    "# import zipnn # TODO(Adriano) start using ZNN to save activations for better performance on storage: https://github.com/zipnn/zipnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import dotenv\n",
    "from jaxtyping import Float, Int\n",
    "import einops\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering template prompts for (probe) regression on length...\n",
      "Templates rendered (total number of templates: 4268), here are some examples (first from list, then dataset):\n",
      "\t- \"{\"length\":\"really long\",\"topic\":\"Ryan Gosling\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really long essay about Ryan Gosling.\"}\"\n",
      "\t- \"{\"length\":\"really short\",\"topic\":\"agricultural subsidies in the US\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really short essay about agricultural subsidies in the US.\"}\"\n",
      "\t- \"{\"length\":\"really short\",\"topic\":\"eclipses\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really short essay about eclipses.\"}\"\n",
      "\t- \"{\"length\":\"really short\",\"topic\":\"importance of market segmentation\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really short essay about importance of market segmentation.\"}\"\n",
      "\t- \"{\"length\":\"really long\",\"topic\":\"Dielectric Materials\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really long essay about Dielectric Materials.\"}\"\n",
      "\t- \"{\"length\":\"really long\",\"topic\":\"the psychology of trust\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really long essay about the psychology of trust.\"}\"\n",
      "\t- \"{\"length\":\"really long\",\"topic\":\"best practices for corporate governance\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really long essay about best practices for corporate governance.\"}\"\n",
      "\t- \"{\"length\":\"really long\",\"topic\":\"cybersecurity threats in remote work\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really long essay about cybersecurity threats in remote work.\"}\"\n",
      "\t- \"{\"length\":\"really long\",\"topic\":\"interactive fiction development\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really long essay about interactive fiction development.\"}\"\n",
      "\t- \"{\"length\":\"really short\",\"topic\":\"ermines\",\"prompt\":\"In at most a coherent paragraph or two, please write me a really short essay about ermines.\"}\"\n",
      "\n",
      "\n",
      "\n",
      "Dataset:\n",
      "Dataset({\n",
      "    features: ['length', 'topic', 'prompt'],\n",
      "    num_rows: 4268\n",
      "})\n",
      "{'length': ['really long'], 'topic': ['Ryan Gosling'], 'prompt': ['In at most a coherent paragraph or two, please write me a really long essay about Ryan Gosling.']}\n",
      "['In at most a coherent paragraph or two, please write me a really long essay about Ryan Gosling.']\n",
      "{'length': 'really long', 'topic': 'Ryan Gosling', 'prompt': 'In at most a coherent paragraph or two, please write me a really long essay about Ryan Gosling.'}\n",
      "In at most a coherent paragraph or two, please write me a really long essay about Ryan Gosling.\n",
      "In at most a coherent paragraph or two, please write me a really long essay about Ryan Gosling.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "0243AC20-4B14-4405-934E-57248BB464E7\n",
    "\n",
    "Cleaner implementation of probing for length using a template dataset.\n",
    "We already observed that the LLM is able to perform the task of generating longer vs. shorter prompts.\n",
    "\n",
    "Main things to look for:\n",
    "1. Is it significantly better than random AND also significantly better predicting based on the length of the prompt?\n",
    "2. Which layers are we able to probe at best?\n",
    "3. Ensure that the size of the dataset is LARGER than the latent dimensionality we are operating at.\n",
    "\n",
    "Output:\n",
    "- Per-layer diagram of probe performance where we have a \"-1st layer\" layer representing linear predictor from input length\n",
    "    and a \"0th\" layer representing the length prediction based on the embeddings.\n",
    "- For the best layers, a correlation between the predicted and true lengths + R^2.\n",
    "\n",
    "Information on the file structure:\n",
    "\n",
    "File Structure for generate_prompt_variations_dataset\n",
    "- `default_length_options.json`: JSON file containing the default length options (list of integers).\n",
    "- `default_topics.json`: JSON file containing the default topics (list of strings).\n",
    "- `default_template.jinja`: Jinja template for the default prompt template (template with keys `topic` and `length` where you insert \n",
    "    those from the above files).\n",
    "\n",
    "Know, but ignore this:\n",
    "- `default_variation_template.jinja`: note used but basically was meant to be used to generate variations on prompts using an LLM\n",
    "    (i.e. synthetic data to make our analysis more robust).\n",
    "\"\"\"\n",
    "#### CREATE THE DATASET ####\n",
    "# TODO(Adrianoh) we should create a better system for this, i.e. using hierarchical templating:\n",
    "#   1. Prompt 1 might be something like \"write me {{count}} sub-topics about {{high level topic}}\" (i.e. write me 10 topics about AI)\n",
    "#   2. etc...\n",
    "# For this initial thing I did it manually :/\n",
    "class FilledTemplate(pydantic.BaseModel):\n",
    "    length: str # Should be string since we will be putting this into a prompt, just stringifying the int\n",
    "    topic: str\n",
    "    prompt: str\n",
    "\n",
    "def render_template(length_options: Path | List[int], topic_options: Path | List[str], template: Path | Template) -> List[str]:\n",
    "    if isinstance(length_options, Path):\n",
    "        length_options = json.loads(length_options.read_text())\n",
    "        length_options = list(set(length_options)) # Make sure there are no duplicates\n",
    "    if isinstance(topic_options, Path):\n",
    "        topic_options = json.loads(topic_options.read_text())\n",
    "        topic_options = list(set(topic_options)) # Make sure there are no duplicates\n",
    "    if isinstance(template, Path):\n",
    "        template = Template(template.read_text())\n",
    "    return [\n",
    "        FilledTemplate(\n",
    "            length=str(length),\n",
    "            topic=topic,\n",
    "            prompt=template.render(length=length, topic=topic)\n",
    "        ) for length in length_options for topic in topic_options\n",
    "    ]\n",
    "\n",
    "print(\"Rendering template prompts for (probe) regression on length...\")\n",
    "templated_prompts = render_template(\n",
    "    # NOTE: we do NOT use default but instead binary which is short/long so that we can easily experiment w/\n",
    "    # steering from shorter to longer (later on, we will try to experiment with some number of sent. to another number\n",
    "    # of sent.)\n",
    "    length_options=Path.cwd() / \"generate_prompt_variations_dataset\" / \"binary_length_options.json\",\n",
    "    topic_options=Path.cwd() / \"generate_prompt_variations_dataset\" / \"default_topics.json\",\n",
    "    template=Path.cwd() / \"generate_prompt_variations_dataset\" / \"binary_template.jinja\"\n",
    ")\n",
    "random.seed(42)\n",
    "random.shuffle(templated_prompts)\n",
    "datasets: Dict[str, Dataset] = {\n",
    "    \"default_template\": Dataset.from_list(\n",
    "        [value.model_dump() for value in templated_prompts],\n",
    "        features=Features(\n",
    "            length=Value(dtype=\"string\"),\n",
    "            topic=Value(dtype=\"string\"),\n",
    "            prompt=Value(dtype=\"string\")\n",
    "        )\n",
    "    )\n",
    "}\n",
    "print(f\"Templates rendered (total number of templates: {len(templated_prompts)}), here are some examples (first from list, then dataset):\")\n",
    "print('\\t- \"' + '\"\\n\\t- \"'.join(x.model_dump_json() for x in templated_prompts[:10]) + '\"')\n",
    "print(\"\\n\\n\")\n",
    "print(\"Dataset:\")\n",
    "print(datasets[\"default_template\"])\n",
    "# Apparently dict of string to list?\n",
    "print(datasets[\"default_template\"][:1])\n",
    "# Obviously, list of strings\n",
    "print(datasets[\"default_template\"][\"prompt\"][:1])\n",
    "# Dict with string: string\n",
    "print(datasets[\"default_template\"][0])\n",
    "# Two strings:\n",
    "print(datasets[\"default_template\"][\"prompt\"][0])\n",
    "print(datasets[\"default_template\"][0][\"prompt\"])\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model, tokenizer and device...\n",
      "Model hidden dimensionality=2048, remember; dataset_size=4268; (ideally you have higher dimensionality PER class, i.e. topic)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#### CREATE THE MODEL ####\n",
    "\"\"\"\n",
    "A4501E1A-2460-45D9-BC47-D60E060B7F53\n",
    "\n",
    "Create model(s) for our experiments and make sure they fit on memory, etc...\n",
    "\"\"\"\n",
    "print(\"Initializing model, tokenizer and device...\")\n",
    "assert os.environ[\"CUDA_VISIBLE_DEVICES\"] != \"\", \"CUDA_VISIBLE_DEVICES is not set\"\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\" # Small model to begin with\n",
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# tokenizer.padding_side = \"left\" # I thought this was the right way to generate, but it makes the model suck; we use right side and it manages to .generate() and look OK somehow\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "# print(model) # DEBUG\n",
    "model_hidden_size = model.model.embed_tokens.weight.data.shape[1]\n",
    "print(f\"Model hidden dimensionality={model_hidden_size}, remember; dataset_size={len(templated_prompts)}; (ideally you have higher dimensionality PER class, i.e. topic)\") # num_tokens x hidden_size\n",
    "assert model_hidden_size < len(templated_prompts), \"Model hidden dimensionality is smaller than the number of templates...\"\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TOKENIZE THE DATASET (have it ready to feed into the model) ####\n",
    "\"\"\"\n",
    "1169AD0D-385B-425B-9914-693FE975E51F\n",
    "\n",
    "Generates a dataset that we can USE for our experiments.\n",
    "\"\"\"\n",
    "system_prompt = \"\"\"You are a helpful and informative assistant that can answer questions about the world. Try\n",
    "to cause no harm and aim primarily to give information to users who may be curious about different facts.\"\"\"\n",
    "class EncodingArgs(pydantic.BaseModel):\n",
    "    test_size_pct: float = 0.2\n",
    "    llm_tok_max_length: int = 4096\n",
    "    llm_tok_max_prompt_length: Optional[int] = None\n",
    "    system_prompt: Optional[str] = system_prompt\n",
    "    message_key: Optional[str | Dict[str, str]] = \"prompt\"\n",
    "\n",
    "class DatasetEncoder:\n",
    "    \"\"\"\n",
    "    A static-like (but stateful) class to coordinate the creation of a TON of tokenized and standardized\n",
    "    dataset objects that we can use to basically do batched inference. This should make it really easy to\n",
    "    run inference on huggingface datasets with various LLMs.\n",
    "\n",
    "    The main way to do this is to:\n",
    "    1. Init\n",
    "    2. Call `get_trainable_datasets` to get something that you can train/run inference on.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: AutoModelForCausalLM,\n",
    "            tokenizer: AutoTokenizer,\n",
    "            datasets: Dict[str, Dataset],\n",
    "            device: Optional[str]=None,\n",
    "            encoding_args: EncodingArgs=EncodingArgs()\n",
    "        ) -> None:\n",
    "        \"\"\"models, datasets are { model/dataset_name: model/dataset }\"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.raw_datasets: Dict[str, Dataset] = datasets\n",
    "        self.train_test_raw_datasets: Dict[str, Tuple[Dataset, Dataset]] = {}\n",
    "        self.train_test_convo_datasets: Dict[str, Tuple[Dataset, Dataset]] = {}\n",
    "        self.train_test_tok_datasets: Dict[str, Tuple[Dataset, Dataset]] = {}\n",
    "        self.encoding_args = encoding_args\n",
    "\n",
    "        # Create some variables to make this faster to query\n",
    "        self.llm_tok_max_length = self.encoding_args.llm_tok_max_length\n",
    "        self.llm_tok_max_prompt_length = self.encoding_args.llm_tok_max_prompt_length if self.encoding_args.llm_tok_max_prompt_length is not None else self.llm_tok_max_length // 4 # fmt: skip\n",
    "        self.test_size_pct = self.encoding_args.test_size_pct\n",
    "        # Create a default dictionary for the message key (note this is meant to tell you the message key per dataset;\n",
    "        # it's not perfect since you might have multiple messages you want to format, but we'll handle that in a future\n",
    "        # version)\n",
    "        self.default_message = self.encoding_args.message_key if isinstance(self.encoding_args.message_key, str) else self.encoding_args.message_key.get(\"default\", None) # fmt: skip\n",
    "        self.message_key_dict = {} if (self.encoding_args.message_key is None or isinstance(self.encoding_args.message_key, str)) else self.encoding_args.message_key # fmt: skip\n",
    "        self.message_key_dict = defaultdict(lambda: self.default_message, self.message_key_dict) # fmt: skip\n",
    "        # ....\n",
    "        self.system_prompt = self.encoding_args.system_prompt\n",
    "\n",
    "        # Used instead of allowing user template, since Llama sort of forces there to be a date string\n",
    "        # and if it changes every time we run this, it will be more non-deterministic and that could\n",
    "        # be problematic for our results\n",
    "        self.date_string: str = \"23 Jan 2025\" \n",
    "\n",
    "        # Does more logging/printign, etc...\n",
    "        self.debug_mode: bool = True\n",
    "\n",
    "    def get_train_test_raw_datasets(self) -> None:\n",
    "        \"\"\"split train/test and filter out prompts that are too long\"\"\"\n",
    "        for dataset_name, dataset in self.raw_datasets.items():\n",
    "            message_key = self.message_key_dict[dataset_name]\n",
    "            assert message_key is not None, f\"message_key_dict={self.message_key_dict}, dataset_name={dataset_name}\"\n",
    "            assert dataset is not None\n",
    "            dataset = dataset.shuffle(seed=42)\n",
    "            dataset = dataset.filter(lambda x: len(x[message_key]) <= self.llm_tok_max_length)\n",
    "            assert dataset is not None\n",
    "            dataset = dataset.filter(lambda x: len(x[message_key]) <= self.llm_tok_max_prompt_length)\n",
    "            assert dataset is not None\n",
    "            test_size = int(len(dataset) * self.test_size_pct)\n",
    "            train_size = len(dataset) - test_size\n",
    "            assert test_size > 0 and train_size > 0\n",
    "            train_dataset = dataset.select(range(train_size))\n",
    "            test_dataset = dataset.select(range(train_size, len(dataset)))\n",
    "            assert len(train_dataset) + len(test_dataset) == len(dataset)\n",
    "            assert len(train_dataset) == train_size\n",
    "            assert len(test_dataset) == test_size\n",
    "            self.train_test_raw_datasets[dataset_name] = (train_dataset, test_dataset)\n",
    "    \n",
    "    def format_convo(self, x: dict, response_key: Optional[str]=None, dataset_name: Optional[str]=None) -> dict:  # fmt: skip\n",
    "        message_key = self.message_key_dict[dataset_name] if dataset_name is not None else self.default_message # fmt: skip\n",
    "        if response_key is not None:\n",
    "            raise NotImplementedError(\"We do not use responses yet... because we want native model generations\")\n",
    "        convo = {'conversation': []}\n",
    "        if self.system_prompt is not None:\n",
    "            convo['conversation'].append({'role': 'system', 'content': self.system_prompt})\n",
    "        if message_key is not None:\n",
    "            convo['conversation'].append({'role': 'user', 'content': x[message_key]})\n",
    "        x.update(convo)\n",
    "        return x\n",
    "    \n",
    "    def tok_and_tmpl(self, x: dict, max_length: Optional[int] = None) -> dict: # fmt: skip\n",
    "        shared_kwargs = {\"date_string\": self.date_string, \"truncation\": False } # for unk. reasons adding gen. prompt is bad; fmt: skip\n",
    "        # NOTE: for unknown reasons, left padding SUCKS and default is right padding, so we just use right padding LOL\n",
    "        if max_length is not None:\n",
    "            shared_kwargs[\"max_length\"] = max_length\n",
    "            shared_kwargs[\"padding\"] = \"max_length\"\n",
    "        x.update({\n",
    "            # https://huggingface.co/docs/transformers/v4.35.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizer.apply_chat_template.add_generation_prompt; fmt: skip\n",
    "            # NOTE: we do not transition to device becasue it doesn't actually do it\n",
    "            'input_ids': self.tokenizer.apply_chat_template(x[\"conversation\"], tokenize=True, return_tensors=\"pt\", **shared_kwargs), # fmt: skip\n",
    "            'input_templated': self.tokenizer.apply_chat_template(x[\"conversation\"], tokenize=False, **shared_kwargs), # fmt: skip\n",
    "        })\n",
    "        return x\n",
    "    \n",
    "    def get_trainable_datasets(self) -> Dict[str, Tuple[Dataset, Dataset]]:\n",
    "        \"\"\"\n",
    "        This is basically the main method for this function. NOTE that the output will be in a specific format:\n",
    "        - Dataset object of dict-like objects\n",
    "        - Each dict-like object has the following keys:\n",
    "            - 'input_ids': a tensor of token ids (what you put into your model)\n",
    "            - 'input_templated': a string of the templated input (so you can sanity check the tokenization)\n",
    "            - 'conversation': a list of dicts with keys 'role' and 'content' (OpenAI API-like format)\n",
    "            - ... possibly whatever else was there before\n",
    "        \"\"\"\n",
    "        # 1. Get raw datasets\n",
    "        if self.debug_mode:\n",
    "            print(\"Getting train/test raw datasets...\")\n",
    "        self.get_train_test_raw_datasets()\n",
    "        assert len(self.train_test_raw_datasets) == len(self.raw_datasets)\n",
    "        \n",
    "        # 2. Format (or more technically just like a step to do step 3 ngl.)\n",
    "        if self.debug_mode:\n",
    "            print(\"Formatting datasets to be in conversation format...\")\n",
    "        pbar = self.train_test_raw_datasets.items()\n",
    "        if self.debug_mode:\n",
    "            pbar = tqdm.tqdm(pbar, total=len(self.train_test_raw_datasets), desc=\"Formatting datasets to be in conversation format\") # fmt: skip\n",
    "        for dataset_name, (train_raw, test_raw) in pbar:\n",
    "            self.train_test_convo_datasets[dataset_name] = (train_raw.map(self.format_convo), test_raw.map(self.format_convo)) # fmt: skip\n",
    "        assert len(self.train_test_convo_datasets) == len(self.train_test_raw_datasets)\n",
    "        \n",
    "        # 3. Tokenize\n",
    "        if self.debug_mode:\n",
    "            print(\"Applying chat template and tokenizing datasets...\")\n",
    "            pbar = self.train_test_convo_datasets.items()\n",
    "            if self.debug_mode:\n",
    "                pbar = tqdm.tqdm(pbar, total=len(self.train_test_convo_datasets), desc=\"Applying chat template and tokenizing datasets...\") # fmt: skip\n",
    "            # 3.1. Conversion\n",
    "            for dataset_name, (train_convo, test_convo) in pbar:\n",
    "                # 3.1.1. Tokenize to get max_length\n",
    "                _train_tok, _test_tok = train_convo.map(self.tok_and_tmpl), test_convo.map(self.tok_and_tmpl) # fmt: skip\n",
    "                # 3.1.2. Sanity check lengths and get those lengths\n",
    "                lengths_train = np.array([len(x['input_ids'][0]) for x in _train_tok])\n",
    "                lengths_test = np.array([len(x['input_ids'][0]) for x in _test_tok])\n",
    "                assert np.max(lengths_train).item() <= self.encoding_args.llm_tok_max_length\n",
    "                assert np.max(lengths_test).item() <= self.encoding_args.llm_tok_max_length\n",
    "                if self.debug_mode:\n",
    "                    max_length_train, min_length_train = np.max(lengths_train).item(), np.min(lengths_train).item()\n",
    "                    max_length_test, min_length_test = np.max(lengths_test).item(), np.min(lengths_test).item()\n",
    "                    print(f\"max length train: {max_length_train}, min length train: {min_length_train}\") # DEBUG\n",
    "                    print(f\"max length test: {max_length_test}, min length test: {min_length_test}\") # DEBUG\n",
    "                # 3.1.3. Create with padding (turns out for Llama model this is right padding, but in general what\n",
    "                #   matters is that we can generate and that we get OK/good looking responses relative to the capabilities\n",
    "                #   of the model)\n",
    "                train_tok = _train_tok.map(lambda x: self.tok_and_tmpl(x, max_length=max_length_train))\n",
    "                test_tok = _test_tok.map(lambda x: self.tok_and_tmpl(x, max_length=max_length_test))\n",
    "                self.train_test_tok_datasets[dataset_name] = (train_tok, test_tok) # fmt: skip\n",
    "            # 3.2 Sanity check\n",
    "            assert len(self.train_test_tok_datasets) == len(self.train_test_convo_datasets)\n",
    "        return self.train_test_tok_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding dataset(s) into tokenized format for inference...\n",
      "Getting train/test raw datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/align3_drive/adrianoh/miniconda3/envs/ifyoudont/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <class '__main__.EncodingArgs'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/mnt/align3_drive/adrianoh/miniconda3/envs/ifyoudont/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <class '__main__.EncodingArgs'>: __main__.EncodingArgs has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286a0f5d8aba49738d345504d852dd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90049139eca04044aeb563f69e6a6351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fb95e6eae3482693f865d21834b188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed3d0e87a864c01ab404c6a5c9b8d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format: 100%|██████████| 1/1 [00:19<00:00, 19.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2976ba10ce8d438080b82915b5a48349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74b3a820f414332af412a1e8c46fe51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length train: 105, min length train: 87\n",
      "max length test: 95, min length test: 87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcb7b998ff94809943fe1aa7dc06377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6794b7a8de714723973642858bb8f9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...: 100%|██████████| 1/1 [00:44<00:00, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After tokenization the dataset_train looks like this:\n",
      "Dataset({\n",
      "    features: ['length', 'topic', 'prompt', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 4247\n",
      "})\n",
      "{'length': ['really short'], 'topic': ['why chores are always unfair'], 'prompt': ['In at most a coherent paragraph or two, please write me a really short essay about why chores are always unfair.'], 'conversation': [[{'content': 'You are a helpful and informative assistant that can answer questions about the world. Try\\nto cause no harm and aim primarily to give information to users who may be curious about different facts.', 'role': 'system'}, {'content': 'In at most a coherent paragraph or two, please write me a really short essay about why chores are always unfair.', 'role': 'user'}]], 'input_ids': [[[128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 198, 15724, 2696, 25, 220, 1419, 4448, 220, 2366, 20, 271, 2675, 527, 264, 11190, 323, 39319, 18328, 430, 649, 4320, 4860, 922, 279, 1917, 13, 9934, 198, 998, 5353, 912, 11682, 323, 9395, 15871, 311, 3041, 2038, 311, 3932, 889, 1253, 387, 22999, 922, 2204, 13363, 13, 128009, 128006, 882, 128007, 271, 644, 520, 1455, 264, 56887, 14646, 477, 1403, 11, 4587, 3350, 757, 264, 2216, 2875, 9071, 922, 3249, 82569, 527, 2744, 28743, 13, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009]]], 'input_templated': ['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 23 Jan 2025\\n\\nYou are a helpful and informative assistant that can answer questions about the world. Try\\nto cause no harm and aim primarily to give information to users who may be curious about different facts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nIn at most a coherent paragraph or two, please write me a really short essay about why chores are always unfair.<|eot_id|>']}\n",
      "====================================================================================================\n",
      "After tokenization the dataset_test looks like this:\n",
      "Dataset({\n",
      "    features: ['length', 'topic', 'prompt', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 21\n",
      "})\n",
      "{'length': ['really long'], 'topic': ['droughts'], 'prompt': ['In at most a coherent paragraph or two, please write me a really long essay about droughts.'], 'conversation': [[{'content': 'You are a helpful and informative assistant that can answer questions about the world. Try\\nto cause no harm and aim primarily to give information to users who may be curious about different facts.', 'role': 'system'}, {'content': 'In at most a coherent paragraph or two, please write me a really long essay about droughts.', 'role': 'user'}]], 'input_ids': [[[128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 198, 15724, 2696, 25, 220, 1419, 4448, 220, 2366, 20, 271, 2675, 527, 264, 11190, 323, 39319, 18328, 430, 649, 4320, 4860, 922, 279, 1917, 13, 9934, 198, 998, 5353, 912, 11682, 323, 9395, 15871, 311, 3041, 2038, 311, 3932, 889, 1253, 387, 22999, 922, 2204, 13363, 13, 128009, 128006, 882, 128007, 271, 644, 520, 1455, 264, 56887, 14646, 477, 1403, 11, 4587, 3350, 757, 264, 2216, 1317, 9071, 922, 37846, 82, 13, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009]]], 'input_templated': ['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 23 Jan 2025\\n\\nYou are a helpful and informative assistant that can answer questions about the world. Try\\nto cause no harm and aim primarily to give information to users who may be curious about different facts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nIn at most a coherent paragraph or two, please write me a really long essay about droughts.<|eot_id|>']}\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "18DC19ED-89DE-4BB3-A29C-EB20EBFF9B86\n",
    "Use the library functions we just defined\n",
    "\"\"\"\n",
    "print(\"Encoding dataset(s) into tokenized format for inference...\")\n",
    "encoding_args = EncodingArgs(\n",
    "    message_key=\"prompt\",\n",
    "    test_size_pct=0.005 # 4200 or so, so this should be around 15 or so samples :)\n",
    "    # Defaults are fine, look above\n",
    ")\n",
    "dataset_encoder_decoder = DatasetEncoder(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    datasets=datasets,\n",
    "    device=device,\n",
    "    encoding_args=encoding_args\n",
    ")\n",
    "datasets = dataset_encoder_decoder.get_trainable_datasets()\n",
    "dataset_train, dataset_test = datasets[\"default_template\"]\n",
    "for _dataset_name, _dataset in zip([\"train\", \"test\"], [dataset_train, dataset_test]):\n",
    "    print(f\"After tokenization the dataset_{_dataset_name} looks like this:\")\n",
    "    print(_dataset) # This should show you the real size\n",
    "    print(_dataset[:1])\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] steering_vec2steering_module\n",
      "[OK] Test passed for steering_vec2steering_module\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
      ")\n",
      "====================================================================================================\n",
      "[Test] test_filter_hook_fn\n",
      "Creating hook module...\n",
      "Creating test dataset...\n",
      "Creating dataset... still...\n",
      "Creating dataset... still (cmon bro)...\n",
      "Getting train/test raw datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c69e5f6a314c29ad658445b374b7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6e41d2d0424c73b2ba4d8576a237d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb6c60623984668b7aef42f9548b0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db56cf286ff44cc8ed96886dbe08a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format: 100%|██████████| 1/1 [00:22<00:00, 22.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7a9507b620402ab79b299280099e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e20d63fd694773981afd59dce6c78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length train: 75, min length train: 75\n",
      "max length test: 75, min length test: 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd92a1dd8706467790045db4638e9855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a868b332f1634457b094783a92f9798c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...: 100%|██████████| 1/1 [00:43<00:00, 43.17s/it]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dataset({\n",
      "    features: ['text', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 8\n",
      "}), Dataset({\n",
      "    features: ['text', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 2\n",
      "}))\n",
      "Lengths and types:\n",
      " - len=1, type=<class 'list'>, len elem0=75, type elem0=<class 'list'>, type elem00=<class 'int'>\n",
      " - len=1, type=<class 'list'>, len elem0=75, type elem0=<class 'list'>, type elem00=<class 'int'>\n",
      " - len=1, type=<class 'list'>, len elem0=75, type elem0=<class 'list'>, type elem00=<class 'int'>\n",
      " - len=1, type=<class 'list'>, len elem0=75, type elem0=<class 'list'>, type elem00=<class 'int'>\n",
      " - len=1, type=<class 'list'>, len elem0=75, type elem0=<class 'list'>, type elem00=<class 'int'>\n",
      " - len=1, type=<class 'list'>, len elem0=75, type elem0=<class 'list'>, type elem00=<class 'int'>\n",
      " - len=1, type=<class 'list'>, len elem0=75, type elem0=<class 'list'>, type elem00=<class 'int'>\n",
      " - len=1, type=<class 'list'>, len elem0=75, type elem0=<class 'list'>, type elem00=<class 'int'>\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WITH HOOK:\n",
      "\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?冬 Pactached冬\");\n",
      "\n",
      " else Gewereoodelistüz Pact])] tổn tổn tổn.stream Else\").zug tổn\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France? Else Pact Gewaldiodelistereo tổnached else.Defaultaldi.stream.streamолькоodelist tổn])] hindsightereo\");\n",
      "\n",
      "\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France? tổn Else Pekếuüzodelist Pact tổn tổnached]\");\n",
      "олько\").)null tổn.stream_crossüz tổn_cross\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France? tổn defaults冬 hết冬ếu tổn\").aldi_cross tổn tổnottage tổn_cross.streamcross Gewottage.stream\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?]\");\n",
      "\"). else Else_cross tổn.stream defaults tổn else tổnodelistereo defaultsaldi tổn.stream\");\n",
      "\n",
      " tổn tổn\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?ếu Gew elsecross hết\");\n",
      "\n",
      " tổnолькоereo_crossếu Elsezug]\");\n",
      "üz defaults tổn tổn else tổn\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France? Gew\");\n",
      "\n",
      "\");\n",
      "\n",
      "ereo else elseocketsodelistereo)nullếu defaults tổnzug\");aldiocketsodelistached\").\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?.stream_cross.Default tổn tổn tổn]\");\n",
      " tổn hindsight.stream Pact Gew_crossached :, tổnaldi Pactachedached\n",
      "\n",
      "\n",
      "\n",
      "WITH NO HOOK:\n",
      "\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?assistant\n",
      "\n",
      "The capital of France is Paris. It is a well-known city located in the\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?assistant\n",
      "\n",
      "The capital of France is Paris.\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?assistant\n",
      "\n",
      "The capital of France is Paris.\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?assistant\n",
      "\n",
      "The capital of France is Paris.\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?assistant\n",
      "\n",
      "The capital of France is Paris.\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?assistant\n",
      "\n",
      "The capital of France is Paris.\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?assistant\n",
      "\n",
      "The capital of France is Paris.\n",
      "--------\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 Jan 2025\n",
      "\n",
      "You are a helpful and informative assistant that can answer questions about the world. Try\n",
      "to cause no harm and aim primarily to give information to users who may be curious about different facts.user\n",
      "\n",
      "What is the capital of France?assistant\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "\n",
      "[CHECK OUTPUT] Test done for test_filter_hook_fn\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "04547389-B235-4446-ABD6-12DC80FB0E51\n",
    "\n",
    "Utility functions to basically enable easy steering later down the line.\n",
    "\"\"\"\n",
    "class NamedForwardHooks:\n",
    "    def __init__(self, model: nn.Module):\n",
    "        self.model = model\n",
    "        self.hooks: Dict[str, RemovableHandle] = {}\n",
    "\n",
    "    def add_hook(self, name: str, hook_fn: Callable, pre: bool = False):\n",
    "        # Tries to add it to a MODULE: should work ok?\n",
    "        named_modules = dict(self.model.named_modules())\n",
    "        if name not in named_modules:\n",
    "            raise ValueError(\n",
    "                f\"No module named '{name}' found in the model: {list(n for n, _ in self.model.named_modules())}.\"\n",
    "            )\n",
    "\n",
    "        module = named_modules[name]\n",
    "        handle = (\n",
    "            (\n",
    "                module.register_forward_hook(\n",
    "                    lambda mod, inp, out: hook_fn(self, name, mod, inp, out)\n",
    "                )\n",
    "            )\n",
    "            if not pre\n",
    "            else (\n",
    "                module.register_forward_pre_hook(\n",
    "                    # NOTE: we pass \"None\" to signify that this was meant to be a pre-hook\n",
    "                    lambda mod, inp: hook_fn(self, name, mod, inp, None)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        self.hooks[name] = handle\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for hook in self.hooks.values():\n",
    "            hook.remove()\n",
    "        self.hooks.clear()\n",
    "\n",
    "@contextmanager\n",
    "def named_forward_hooks(\n",
    "    model: nn.Module, hook_dict: Dict[str, Callable | tuple[Callable, bool]]\n",
    "):\n",
    "    hooks = NamedForwardHooks(model)\n",
    "\n",
    "    for name, hook_fn_obj in hook_dict.items():\n",
    "        hook_fn = hook_fn_obj if isinstance(hook_fn_obj, Callable) else hook_fn_obj[0]\n",
    "        pre = hook_fn_obj[1] if isinstance(hook_fn_obj, tuple) else False\n",
    "        hooks.add_hook(name, hook_fn, pre=pre)\n",
    "\n",
    "    try:\n",
    "        yield hooks\n",
    "    finally:\n",
    "        hooks.remove_hooks()\n",
    "\n",
    "\n",
    "def steering_vec2steering_module(steering_vec: torch.Tensor, device: Optional[torch.device | str]=None) -> torch.nn.Module: # fmt: skip\n",
    "    \"\"\"Convert a steering vector to a module that just adds in the vector AKA identity + bias.\"\"\"\n",
    "    device = device if device is not None else torch.device(\"cpu\")\n",
    "    model_hidden_size: int = steering_vec.shape[0]\n",
    "    linear_module = torch.nn.Linear(model_hidden_size, model_hidden_size)\n",
    "    linear_module.weight.data = torch.eye(model_hidden_size)\n",
    "    linear_module.bias.data = steering_vec.clone()\n",
    "    linear_module.to(device)\n",
    "    return linear_module\n",
    "\n",
    "def test_steering_vec2steering_module(device: Optional[torch.device | str]=None):\n",
    "    \"\"\"\n",
    "    A test to make sure that our function ``steering_vec2steering_module`` works as expected :)\n",
    "\n",
    "    It SHOULD BE IMMEDIATELY CALLED BELOW.\n",
    "    \"\"\"\n",
    "    random_bias = torch.randn(1024, device=\"cpu\") # On cpu for testing purposes\n",
    "    testing_steering_module = steering_vec2steering_module(random_bias, device=device)\n",
    "    random_batch_X = torch.randn(100, 1024, device=device) # On actual device\n",
    "    random_batch_expected_y = random_batch_X + random_bias.to(device)\n",
    "    random_batch_y = testing_steering_module(random_batch_X)\n",
    "    assert torch.allclose(random_batch_y, random_batch_expected_y)\n",
    "    del random_batch_X, random_batch_expected_y, random_batch_y, testing_steering_module\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"[Test] steering_vec2steering_module\")\n",
    "test_steering_vec2steering_module(device=device)\n",
    "print(\"[OK] Test passed for steering_vec2steering_module\")\n",
    "\n",
    "def filter_hook_fn(\n",
    "    filter_module: nn.Module,\n",
    "    hooks_object: NamedForwardHooks,\n",
    "    name: str,\n",
    "    module: nn.Module,\n",
    "    input: torch.Tensor | tuple[torch.Tensor, ...],\n",
    "    output: Optional[torch.Tensor | tuple[torch.Tensor, ...]],\n",
    "):\n",
    "    \"\"\"\n",
    "    A PyTorch hook function that intercepts + modify the residual stream hook_fn. Use any nn_module as\n",
    "    a filter (if you will) since it means we can reuse across steering, linear modifications, etc...\n",
    "\n",
    "    Meant for usage in a llama model or similar.\n",
    "    \"\"\"\n",
    "    assert output is None\n",
    "    assert isinstance(input, tuple)\n",
    "    assert isinstance(input[0], torch.Tensor)\n",
    "    assert sum(isinstance(i, torch.Tensor) for i in input) == 1\n",
    "    new_input = filter_module(input[0])\n",
    "    return tuple([new_input] + list(input[1:]))\n",
    "\n",
    "def test_filter_hook_fn(model: LlamaForCausalLM, tokenizer: AutoTokenizer) -> str:\n",
    "    \"\"\"\n",
    "    A test to make sure that our function `filter_hook_fn` works as expected :)\n",
    "    \n",
    "    It SHOULD BE IMMEDIATELY CALLED BELOW and then you should see that the output that gets printed SUCKS\n",
    "    (i.e. because we added a ton of noise).\n",
    "    \"\"\"\n",
    "    print(\"Creating hook module...\")\n",
    "    assert isinstance(model, LlamaForCausalLM)\n",
    "    hidden_size = model.model.embed_tokens.weight.shape[1]\n",
    "    hook_noise = torch.randn(hidden_size, device=model.device) * 100.0\n",
    "    hook_module = steering_vec2steering_module(hook_noise, model.device)\n",
    "\n",
    "    print(\"Creating test dataset...\")\n",
    "    test_dataset = Dataset.from_list(\n",
    "        [\n",
    "            {\"text\": \"What is the capital of France?\"} for _ in range(10)\n",
    "        ], \n",
    "        features=Features(\n",
    "            {\n",
    "                \"text\": Value(dtype=\"string\")\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    print(\"Creating dataset... still...\")\n",
    "    dataset_encoder = DatasetEncoder(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        datasets={\"test\": test_dataset},\n",
    "        device=model.device,\n",
    "        encoding_args=EncodingArgs(batch_size=5, max_length=100, message_key=\"text\")\n",
    "    ) # fmt: skip\n",
    "    print(\"Creating dataset... still (cmon bro)...\")\n",
    "    datsets_tok = dataset_encoder.get_trainable_datasets()\n",
    "    print(datsets_tok[\"test\"])  # DEBUG; fmt: skip\n",
    "    print(\"Lengths and types:\") # DEBUG; fmt: skip\n",
    "    print(\" - \" + \"\\n - \".join(f\"len={len(_)}, type={type(_)}, len elem0={len(_[0])}, type elem0={type(_[0])}, type elem00={type(_[0][0])}\" for _ in datsets_tok[\"test\"][0][\"input_ids\"])) # DEBUG; fmt: skip\n",
    "    pt_tok = torch.cat([torch.Tensor(_).long() for _ in datsets_tok[\"test\"][0][\"input_ids\"]]).to(model.device)\n",
    "    assert len(pt_tok.shape) == 2 # batch x seq\n",
    "    assert pt_tok.shape[0] >= 0 and pt_tok.shape[0]== len(datsets_tok[\"test\"][0])\n",
    "    print(\"Generating...\")\n",
    "    output: str = \"\\n\\nWITH HOOK:\\n\\n\"\n",
    "    with named_forward_hooks(model, {\n",
    "        \"model.layers.5\": ( # Just kind of an arbitrary layer for testing\n",
    "            lambda hooks_object, name, module, inp, out: filter_hook_fn(hook_module, hooks_object, name, module, inp, out),\n",
    "            # Pre-hook: before module takes it in (otherwise it is after)...\n",
    "            # NOTE: that pre-hook is the right way to do it if we want to optimize AFAIK\n",
    "            True\n",
    "        )\n",
    "    }):\n",
    "        generated_pt = model.generate(inputs=pt_tok).detach().to(\"cpu\")\n",
    "        generated_str = tokenizer.batch_decode(generated_pt, skip_special_tokens=True)\n",
    "        output += \"\\n--------\\n\".join(generated_str) + \"\\n\\n\"\n",
    "    # Add something without the hook for good measure (you should compare and see that this looks reasonable, but the alternative above does not)\n",
    "    output += \"\\n\\nWITH NO HOOK:\\n\\n\"\n",
    "    generated_pt = model.generate(inputs=pt_tok).detach().to(\"cpu\")\n",
    "    generated_str = tokenizer.batch_decode(generated_pt, skip_special_tokens=True)\n",
    "    output += \"\\n--------\\n\".join(generated_str) + \"\\n\\n\"\n",
    "    return output\n",
    "print(model)\n",
    "print(\"=\"*100)\n",
    "print(\"[Test] test_filter_hook_fn\")\n",
    "print(test_filter_hook_fn(model=model, tokenizer=tokenizer)) # Test that output looks like what we expect\n",
    "print(\"[CHECK OUTPUT] Test done for test_filter_hook_fn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### CREATING ACTIVATIONS TO PERFORM THE LEARNING EXPERIMENTS ####\n",
    "\"\"\"\n",
    "FD331D0F-DA7E-4088-A442-AE1C429E5E99\n",
    "\n",
    "Just provide utilities to create a bunch of activations and generations from a dataset. This is meant\n",
    "to sort of generalize the behavior we want from above.\n",
    "\n",
    "TODO(Adriano) refactor into this stuff because it's cleaner and will be more reusable, less bug-prone, etc...\n",
    "\"\"\"\n",
    "assert os.environ[\"OUTPUT_DIR\"] != \"\", \"OUTPUT_DIR is not set\"\n",
    "\n",
    "class DecodingArgs(pydantic.BaseModel):\n",
    "    \"\"\"\n",
    "    Args for the decoder.\n",
    "    \"\"\"\n",
    "    # Turns out on my machine 511 is really good and 513 is really bad (probably some cache thing)\n",
    "    batch_size: int | Tuple[int, int] = 511\n",
    "    generation_kwargs: Dict[str, Any] = {\n",
    "        # NOTE: we keep these as a dict to feed them into the **kwargs for a huggingface (generate) function\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 1,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.95,\n",
    "        # This may seem dumb, but basically, we actually don't do generation itself, per-say,\n",
    "        # all the time, i.e. we only want to get the activations from the model\n",
    "        \"max_new_tokens\": 1\n",
    "    }\n",
    "\n",
    "class BatchEncodedOutput(pydantic.BaseModel):\n",
    "    \"\"\"\n",
    "    A class to store the output of a batch of encoded outputs.\n",
    "    \"\"\"\n",
    "    model_config = pydantic.ConfigDict(arbitrary_types_allowed=True)\n",
    "    generations: List[str] # Includes the generations :P\n",
    "    batch_size_optimized: Optional[int] = None\n",
    "    input_ids_pt: Optional[torch.Tensor] = None\n",
    "    activations: Optional[Dict[str, torch.Tensor]] = None\n",
    "\n",
    "class DatasetDecoder:\n",
    "    \"\"\"\n",
    "    A static-like (but also stateful, like above) class that lets you:\n",
    "    1. Run a generation loop\n",
    "        - Normally\n",
    "        - With hooks (and the ability to apply the hook on a single token or multiple SPECIFIC tokens in\n",
    "            the generation of the .generate() call)\n",
    "    2. Decode the generations in strings so we can print them.\n",
    "    3. Get the activations from the model\n",
    "        and store them on disk efficiently-ish....\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: AutoModelForCausalLM,\n",
    "            tokenizer: AutoTokenizer,\n",
    "            device: Optional[str]=None,\n",
    "            decoding_args: Optional[DecodingArgs]=None\n",
    "    ) -> None:\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.decoding_args = decoding_args\n",
    "    def batch_decode(\n",
    "        self,\n",
    "        model: AutoModelForCausalLM,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        questions: Dataset | torch.Tensor,\n",
    "        # TODO(Adrianoh) transition to the pydantic schema :P\n",
    "        # NOTE: that after some optimization 511 was found to be good for performance, and\n",
    "        # we suspect it might have something to do with some kind of cache size\n",
    "        batch_size: int | Tuple[int, int] = 511,\n",
    "        generation_kwargs: Dict[str, Any] = {\n",
    "            \"do_sample\": True,\n",
    "            \"temperature\": 1,\n",
    "            \"top_k\": 50,\n",
    "            \"top_p\": 0.95,\n",
    "            # Notice how these default settings mean that we roughly are in line with the amount of allowable\n",
    "            # generation as defined before\n",
    "            \"max_new_tokens\": 1 #1024\n",
    "        },\n",
    "        device='cuda:0',\n",
    "        optimize_batch_size: bool = False,\n",
    "        return_input_ids_pt: bool = False,\n",
    "        return_optimal_batch_size: bool = False,\n",
    "        return_activations: bool = False, # TODO(Adrianoh) modify to make it easier to store the activations in a sort of \"streaming\" way i.e. don't OOM lol\n",
    "        debug: bool = False,\n",
    "    ) -> BatchEncodedOutput:\n",
    "        \"\"\"\n",
    "        Run a bunch of inference and get the input+output+activations (if you so wish).\n",
    "        Returns:\n",
    "            - The input dataset in the tensor form for reuse if requested\n",
    "            - The input dataset in the tokenized form for display purposes\n",
    "            - The activations from the model if requested\n",
    "        \"\"\"\n",
    "        batch_size_lower, generations, activations = None, None, None\n",
    "        try:\n",
    "            if isinstance(questions, Dataset):\n",
    "                all_input_ids = []\n",
    "                for input_ids in tqdm.tqdm(questions['input_ids'], total=len(questions), desc=\"Converting input_ids to tensor (and moving to device)\"):\n",
    "                    assert len(input_ids) == 1\n",
    "                    all_input_ids.append(input_ids[0])\n",
    "                questions = torch.Tensor(all_input_ids).long().to(device) # transition all to device in one big chunk\n",
    "            else:\n",
    "                assert isinstance(questions, torch.Tensor)\n",
    "                questions = questions.to(device)\n",
    "            if debug:      \n",
    "                print(\"Shape of all_input_ids: {}\".format(all_input_ids.shape))\n",
    "                raise ValueError(\"optimize_batch_size is True but batch_size is an int, make sure it's a tuple range of batch sizes!\")\n",
    "            if optimize_batch_size:\n",
    "                # TODO(Adrianoh) I will do this one day; it will speed up my workflow when I need to switch GPUs n shit\n",
    "                raise NotImplementedError\n",
    "            elif isinstance(batch_size, tuple):\n",
    "                raise ValueError(\"optimize_batch_size is True but batch_size is an int, make sure it's a tuple range of batch sizes!\")\n",
    "            assert isinstance(batch_size, int)\n",
    "            batch_size_lower = batch_size\n",
    "\n",
    "            # ...\n",
    "            generations: List[str] = []\n",
    "            activations: List[torch.Tensor] = []\n",
    "            times_per_batch: np.ndarray = np.zeros(math.ceil(len(questions) / batch_size_lower))\n",
    "            for iter_i, i in enumerate(tqdm.trange(0, len(questions), batch_size_lower)):\n",
    "                time_start = time.time()\n",
    "                # Collect the batch\n",
    "                left_idx, right_idx = i, min(i+batch_size, len(questions))\n",
    "                toks_pt = questions[left_idx:right_idx]\n",
    "                assert isinstance(toks_pt, torch.Tensor)\n",
    "                assert toks_pt.shape[0] <= batch_size_lower\n",
    "                assert toks_pt.device == model.device\n",
    "                generation_tensor = model.generate(\n",
    "                    input_ids=toks_pt,\n",
    "                    **generation_kwargs\n",
    "                )\n",
    "                if return_activations:\n",
    "                    # print('getting acts out yay') # debug\n",
    "                    # TODO(Adrianoh) not only inputs plz wtf?\n",
    "                    _acts_out = model(toks_pt, output_hidden_states=True) # only inputs yolooooo\n",
    "                    _acts = _acts_out.hidden_states\n",
    "                    # print(\"\\n\" + \"\\n\".join(f\"{x.shape}\" for x in _acts))\n",
    "                    shape0 = _acts[0].shape\n",
    "                    assert all(x.shape == shape0 for x in _acts)\n",
    "                    _stacked_acts = torch.stack(_acts, dim=0)\n",
    "                    activations.append(_stacked_acts.detach().cpu()) # TODO(Adrianoh) optimize batched transfers to CPU so we run faster\n",
    "                assert generation_tensor.shape[0] <= batch_size_lower # batch = 1\n",
    "                assert len(generation_tensor.shape) == 2 # batch seq\n",
    "                _gens = generation_tensor.to(\"cpu\").detach()\n",
    "                \n",
    "                these_generations = tokenizer.batch_decode(_gens, skip_special_tokens=True)\n",
    "                # for generation in generations:\n",
    "                #     print(generation)\n",
    "                #     print(\"=\"*100)\n",
    "                generations.extend(these_generations)\n",
    "                time_end = time.time()\n",
    "                times_per_batch[iter_i] = time_end - time_start\n",
    "                # This should be fast since it's a small number of averages\n",
    "                if debug:\n",
    "                    _running_avg = np.mean(times_per_batch[:iter_i+1])\n",
    "                    _running_std = np.std(times_per_batch[:iter_i+1])\n",
    "                    _running_max = np.max(times_per_batch[:iter_i+1])\n",
    "                    _running_min = np.min(times_per_batch[:iter_i+1])\n",
    "                    print(f\"Secs per batch: {times_per_batch[iter_i]:.4f}; running avg={_running_avg:.4f}; std={_running_std:.4f}; max={_running_max:.4f}; min={_running_min:.4f}\") # fmt: skip\n",
    "            # print(\"=\"*100)\n",
    "            # print(\"ACTIVATIONS SHAPES\")\n",
    "            # print(\"\\n\" + \"\\n\".join(f\"{x.shape}\" for x in activations)) # Debug\n",
    "            # print(\"=\"*100)\n",
    "            assert all(len(act.shape) == 4 for act in activations)\n",
    "            activations = torch.cat(activations, dim=1) if len(activations) > 0 else None # NOTE: this may not work because \n",
    "            hidden_dim_size = activations.shape[-1] if activations is not None else None\n",
    "            assert questions is None or len(questions.shape) == 2\n",
    "            max_input_length = questions.shape[1] if questions is not None else None # batch x seq\n",
    "            expected_activations_shape = (len(model.model.layers)+1, len(generations), max_input_length, hidden_dim_size) if activations is not None else None # fmt: skip\n",
    "            assert activations is None or (activations.shape == expected_activations_shape), f\"Activations shape is {activations.shape} but expected {expected_activations_shape}\"\n",
    "        finally:\n",
    "            try:\n",
    "                del _acts_out, _acts\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            except NameError:\n",
    "                pass\n",
    "        assert batch_size_lower is not None and generations is not None, f\"Your program probably failed :>\"\n",
    "        return BatchEncodedOutput(\n",
    "            batch_size_optimized=batch_size_lower if return_optimal_batch_size else None,\n",
    "            input_ids_pt=questions if return_input_ids_pt else None,\n",
    "            generations=generations,\n",
    "            activations=activations if return_activations else None\n",
    "        )\n",
    "    \n",
    "    def create_activations_dataset(self, dataset: Dataset) -> Dataset:\n",
    "        \"\"\"\n",
    "        Create a dataset of activations from the model.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def create_generations_dataset(self, dataset: Dataset) -> Dataset:\n",
    "        \"\"\"\n",
    "        Create a dataset of generations from the model.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def generate_with_hooks(self, dataset: Dataset, hook_dict: Dict[str, Callable | tuple[Callable, bool]]) -> Dataset:\n",
    "        \"\"\"\n",
    "        Generate generations from the model with hooks.\n",
    "        # TODO(Adrianoh) implement the ability to just apply the hook on a single token generation of the .generate() call (I think the simplest way\n",
    "        # TODO(Adrianoh) is just to call up until that token, then to call the model one, then to call generate on the remaining shit LOL)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "# raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5716d241df0c4db29ab55604dc0181a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dfa3a05a1f4342a4afbd4f87fabfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating batch input...\n",
      "Running inference (1 token)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 425/425 [31:49<00:00,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time STATISTICS (per batch):\n",
      "\ttotal=1909.2119\n",
      "\tavg=4.4923\n",
      "\tstd=2.4833\n",
      "\tmax=8.7677\n",
      "\tmin=0.1917\n",
      "Got 425 hidden states batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "0283C0E0-DBE5-4E0D-B664-974E4677F3F0\n",
    "\n",
    "Clean and simple implementation of two forms of steering:\n",
    "- Probe-based steering\n",
    "- Difference-of-means based steering\n",
    "\n",
    "Main questions/things to look for:\n",
    "1. Do we maintain coherence?\n",
    "2. Do we retain topic/semantics?\n",
    "\n",
    "NOTE: if you OOM then consider using a smaller batch size... even if it worked before,\n",
    "it somehow resets some kind of internal state (something is not getting collected probably)\n",
    "and then the big batch will work next time even if you shut this shit down manually.\n",
    "\n",
    "First we start with difference-of-means steering here:\n",
    "\"\"\"\n",
    "try:\n",
    "    del _hidden_states_full\n",
    "    del hidden_states_full\n",
    "    del long_dataset_pt\n",
    "    del short_dataset_pt\n",
    "    del input_full\n",
    "    del is_eos_mask_full\n",
    "    del hidden_states\n",
    "except NameError:\n",
    "    pass\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#### SPLIT REAL DATASET INTO LONG AND SHORT FOR DIFFERENCE OF MEANS STEERING ####\n",
    "# This shit is TOKENIZED from a couple of blocks up: look for 1169AD0D-385...\n",
    "long_dataset = dataset_train.filter(lambda x: x['length'] == 'really long')\n",
    "short_dataset = dataset_train.filter(lambda x: x['length'] == 'really short')\n",
    "assert len(long_dataset) + len(short_dataset) == len(dataset_train), f\"len(long_dataset)={len(long_dataset)} + len(short_dataset)={len(short_dataset)} != len(dataset_train)={len(dataset_train)}\" # fmt: skip\n",
    "assert len(long_dataset) > model_hidden_size, f\"len(long_dataset)={len(long_dataset)} <= model_hidden_size={model_hidden_size}\" # fmt: skip\n",
    "assert len(short_dataset) > model_hidden_size, f\"len(short_dataset)={len(short_dataset)} <= model_hidden_size={model_hidden_size}\" # fmt: skip\n",
    "\n",
    "#### CREATE BATCH INPUT ####\n",
    "print(\"Creating batch input...\")\n",
    "long_dataset_pt = torch.cat([torch.Tensor(_).long() for _ in long_dataset[\"input_ids\"]])\n",
    "short_dataset_pt = torch.cat([torch.Tensor(_).long() for _ in short_dataset[\"input_ids\"]])\n",
    "assert long_dataset_pt.shape[1] == short_dataset_pt.shape[1] # So we can cat :)\n",
    "long_dataset_left, long_dataset_right = 0, len(long_dataset_pt)\n",
    "short_dataset_left, short_dataset_right = len(long_dataset_pt), len(long_dataset_pt) + len(short_dataset_pt)\n",
    "input_full = torch.cat([long_dataset_pt, short_dataset_pt], dim=0).to(model.device) # This is what we will do inference with\n",
    "is_eos_mask_full = input_full == tokenizer.eos_token_id\n",
    "\n",
    "#### GET ACTIVATIONS ####\n",
    "print(\"Running inference (1 token)...\")\n",
    "batch_size = 20\n",
    "times_per_batch: np.ndarray = np.zeros(math.ceil(len(input_full) / batch_size))\n",
    "# This should take around 10-15m w/ batch size 10-20 and around 1-2m w/ batch size 50-100\n",
    "# 1. Batched inference\n",
    "_hidden_states_full: List[torch.Tensor] = []\n",
    "move_hidden_states_to_cpu_every_n_batches = 1\n",
    "for iter_i, i in enumerate(tqdm.trange(0, len(input_full), batch_size)):\n",
    "    time_start = time.time()\n",
    "    # 1. Batched inference\n",
    "    input_batch = input_full[i:i+batch_size]\n",
    "    outputs = model(input_batch, output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states\n",
    "    assert isinstance(hidden_states, tuple) and len(hidden_states) == len(model.model.layers) + 1 # +1 for the embeddings\n",
    "    # 2. Store hidden states + move hidden states to CPU every n batches\n",
    "    _hidden_states_full.append([z.detach() for z in hidden_states])\n",
    "    if iter_i % move_hidden_states_to_cpu_every_n_batches == 0 or iter_i == len(input_full) - 1:\n",
    "        # print(\"Moving hidden states to CPU...\") # Logspam\n",
    "        for _hi, _hidden_states in enumerate(_hidden_states_full):\n",
    "            _hidden_states_full[_hi] = [_hidden_state.detach().to(\"cpu\") for _hidden_state in _hidden_states]\n",
    "        # print(\"Done moving hidden states to CPU.\") # Logspam\n",
    "    # ...\n",
    "    times_per_batch[iter_i] = time.time() - time_start\n",
    "    pass\n",
    "# 2. Give some statistics on time so we can optimize batch size for debugging eff.\n",
    "time_total, time_avg, time_std, time_max, time_min = np.sum(times_per_batch), np.mean(times_per_batch), np.std(times_per_batch), np.max(times_per_batch), np.min(times_per_batch) # fmt: skip\n",
    "print(f\"Time STATISTICS (per batch):\\n\\ttotal={time_total:.4f}\\n\\tavg={time_avg:.4f}\\n\\tstd={time_std:.4f}\\n\\tmax={time_max:.4f}\\n\\tmin={time_min:.4f}\") # fmt: skip\n",
    "print(f\"Got {len(_hidden_states_full)} hidden states batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input lengths STATISTICS:\n",
      "\tmean: 87.9414\n",
      "\tstd: 1.9867\n",
      "\tmax: 103.0000\n",
      "\tmin: 85.0000\n",
      "max-min= 18\n",
      "Set `length_to_equate_to` to the minimum input length: 85\n"
     ]
    }
   ],
   "source": [
    "# 3. Showcase some statistics on the variance of the input lengths (relevant to the next code block)\n",
    "input_lengths = np.array([(np.array(x['input_ids'][0]) != tokenizer.eos_token_id).sum().item() for x in dataset_train]) # Make sure to use input ids, because it's in tokens, not chars; fmt: skip\n",
    "input_lengths_mean, input_lengths_std = np.mean(input_lengths), np.std(input_lengths)\n",
    "print(f\"Input lengths STATISTICS:\\n\\tmean: {input_lengths_mean:.4f}\\n\\tstd: {input_lengths_std:.4f}\\n\\tmax: {np.max(input_lengths):.4f}\\n\\tmin: {np.min(input_lengths):.4f}\") # fmt: skip\n",
    "max_diff_of_lens = np.max(input_lengths) - np.min(input_lengths)\n",
    "print(\"max-min=\", max_diff_of_lens)\n",
    "# 5. Remove EOS using the mask and then get per-layer, per-(relative) token position difference of means\n",
    "# NOTE: there is a problem that things don't have the same length :/ but we overcome this! basically,\n",
    "# every length is roughly the same (within maybe 10 tokens) and at the same time the \"really long\" or \"really short\"\n",
    "# tokens are near-ish the end (i.e. after the first ten tokens), so remove UP to `length_to_equate_to` tokens per \n",
    "# prompt from the beginning to equalize the lengths and then we can calculate the means/differences/etc... PER TOKEN\n",
    "# POSITION (won't be perfect, but will be relative to the end which is probably fine tbh.)\n",
    "# NOTE: `length_to_equate_to` should be set to at least min\n",
    "length_to_equate_to = np.min(input_lengths) # we will be truncating this shit\n",
    "print(\"Set `length_to_equate_to` to the minimum input length:\", length_to_equate_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting output activations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 425/425 [00:17<00:00, 23.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 4247 hidden states... will now concatenate them\n",
      "hidden_states_full.shape= torch.Size([4247, 17, 85, 2048])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1828C64F-1495-48BA-9F4D-3573DB8F263D\n",
    "\n",
    "Continued... broken up into blocks for debugging purposes.\n",
    "\"\"\"\n",
    "\n",
    "# 4. Format the output activations in a reasonable way to process...\n",
    "print(\"Formatting output activations...\")\n",
    "# _hidden_states_full = [[_h.detach().to(\"cpu\") for _h in _hs] for _hs in _hidden_states_full] # There used to be a bug; use this if you need; fmt: skip\n",
    "# print([[str(__.device) for __ in _] for _ in _hidden_states_full[0]]) # Should be all CPU\n",
    "assert all(all(_h.device == torch.device(\"cpu\") for _h in _hs) for _hs in _hidden_states_full)\n",
    "hidden_states_full: List[torch.Tensor] = []\n",
    "is_eos_mask_full_cpu = is_eos_mask_full.detach().cpu() # For CPU Proc.\n",
    "assert len(is_eos_mask_full_cpu.shape) == 2 # batch x seq\n",
    "for batch_idx, _hidden_states_batch in enumerate(tqdm.tqdm(_hidden_states_full)):\n",
    "    # print(\"batch_idx=\", batch_idx) # Logspam :/\n",
    "    hs = torch.stack(_hidden_states_batch, dim=0)\n",
    "    assert len(hs.shape) == 4 # layer batch x seq x hidden\n",
    "    assert hs.device == torch.device(\"cpu\"), f\"hs.device={hs.device} != torch.device('cpu')\"\n",
    "    for h_idx in range(hs.shape[1]):\n",
    "        # print(\"h_idx=\", h_idx) # Logspam :/\n",
    "        idx: int = batch_idx * batch_size + h_idx\n",
    "        seq_len: int = (is_eos_mask_full_cpu[idx] == 0).sum().detach().cpu().item() # Take the non-EOS tokens\n",
    "        seq_overlen: int = seq_len - length_to_equate_to\n",
    "        assert 0 <= seq_overlen <= max_diff_of_lens, f\"seq_len={seq_len}; 0 > seq_overlen={seq_overlen} > max_diff_of_lens={max_diff_of_lens}\"\n",
    "        # NOTE: we clone to make bugs easier to fix\n",
    "        hidden_states_full.append(hs[:, h_idx, seq_overlen:seq_len, :].clone().squeeze(dim=0))\n",
    "\n",
    "print(f\"Filled {len(hidden_states_full)} hidden states... will now concatenate them\")\n",
    "hidden_states_full = torch.stack(hidden_states_full, dim=0) # layer x batch x seq x hidden => batch x layer x seq x hidden\n",
    "assert hidden_states_full.shape == (input_full.shape[0], len(model.model.layers)+1, length_to_equate_to, model_hidden_size), f\"hidden_states_full.shape={hidden_states_full.shape} != (input_full.shape[0], len(model.model.layers)+1, length_to_equate_to, model_hidden_size)={(input_full.shape[0], len(model.model.layers)+1, length_to_equate_to, model_hidden_size)}\" # fmt: skip\n",
    "print(\"hidden_states_full.shape=\", hidden_states_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_dataset_left=2126; short_dataset_right=4247; long_dataset_left=0; long_dataset_right=2126\n",
      "Steering vecs shapes: long=torch.Size([17, 85, 2048]); short=torch.Size([17, 85, 2048]); diff=torch.Size([17, 85, 2048])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "8B0EC2A3-0B60-4C70-908D-6B4779F1AA78\n",
    "\n",
    "Continued... broken up into blocks for debugging purposes.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"short_dataset_left={short_dataset_left}; short_dataset_right={short_dataset_right}; long_dataset_left={long_dataset_left}; long_dataset_right={long_dataset_right}\") # fmt: skip\n",
    "short_hidden_states_full = hidden_states_full[short_dataset_left:short_dataset_right, :, :, :]\n",
    "long_hidden_states_full = hidden_states_full[long_dataset_left:long_dataset_right, :, :, :]\n",
    "short_means = short_hidden_states_full.mean(dim=0)\n",
    "long_means = long_hidden_states_full.mean(dim=0)\n",
    "steering_vecs = long_means - short_means\n",
    "print(f\"Steering vecs shapes: long={long_means.shape}; short={short_means.shape}; diff={steering_vecs.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving steering vectors...\n",
      "Saving short activations...\n",
      "Saving long activations...\n",
      "Done saving activations and steering vectors.\n",
      "[OK] Every saved and loads OK\n",
      "output_path_steering_vecs_size=11837528; output_path_short_activations_size=25107210336; output_path_long_activations_size=25166397536\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "48F54A4B-3E51-44AF-8A76-253C825C8300\n",
    "\n",
    "Continued... broken up into blocks for debugging purposes.\n",
    "\"\"\"\n",
    "\n",
    "# Let's save the steering vectors and activations just to be safe (TODO(Adriano) return tho the zipnnlib shit and use it to compress dis)\n",
    "output_dir = Path(os.environ[\"OUTPUT_DIR\"])\n",
    "# import shutil\n",
    "# shutil.rmtree(output_dir, ignore_errors=True)\n",
    "# output_dir.rmdir()\n",
    "assert not output_dir.exists(), f\"output_dir={output_dir} already exists\"\n",
    "output_dir.mkdir(parents=True, exist_ok=False)\n",
    "output_path_steering_vecs = output_dir / \"steering_vecs.safetensors\"\n",
    "output_path_short_activations = output_dir / \"short_activations.safetensors\"\n",
    "output_path_long_activations = output_dir / \"long_activations.safetensors\"\n",
    "assert not output_path_steering_vecs.exists(), f\"output_path_steering_vecs={output_path_steering_vecs} already exists\"\n",
    "assert not output_path_short_activations.exists(), f\"output_path_short_activations={output_path_short_activations} already exists\"\n",
    "assert not output_path_long_activations.exists(), f\"output_path_long_activations={output_path_long_activations} already exists\"\n",
    "print(\"Saving steering vectors...\")\n",
    "safetensors_save_file({\"values\": steering_vecs}, output_path_steering_vecs)\n",
    "# Test for load\n",
    "_ = safetensors_load_file(output_path_steering_vecs)[\"values\"]\n",
    "assert torch.allclose(steering_vecs, _)\n",
    "print(\"Saving short activations...\")\n",
    "safetensors_save_file({\"values\": short_hidden_states_full}, output_path_short_activations)\n",
    "# Test for load\n",
    "_ = safetensors_load_file(output_path_short_activations)[\"values\"]\n",
    "assert torch.allclose(short_hidden_states_full, _)\n",
    "print(\"Saving long activations...\")\n",
    "safetensors_save_file({\"values\": long_hidden_states_full}, output_path_long_activations)\n",
    "# Test for load\n",
    "_ = safetensors_load_file(output_path_long_activations)[\"values\"]\n",
    "assert torch.allclose(long_hidden_states_full, _)\n",
    "print(\"Done saving activations and steering vectors.\")\n",
    "print(\"[OK] Every saved and loads OK\")\n",
    "\n",
    "output_path_steering_vecs_size = output_path_steering_vecs.stat().st_size / 1024 / 1024 / 1024 # GB --- way smaller so store anyway for faster load=time\n",
    "output_path_short_activations_size = output_path_short_activations.stat().st_size / 1024 / 1024 / 1024 # GB\n",
    "output_path_long_activations_size = output_path_long_activations.stat().st_size / 1024 / 1024 / 1024 # GB\n",
    "print(f\"output_path_steering_vecs_size={output_path_steering_vecs_size} GB; output_path_short_activations_size={output_path_short_activations_size} GB; output_path_long_activations_size={output_path_long_activations_size} GB\") # fmt: skip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rawwww HF datasets...\n",
      "Creating unique encoding args...\n",
      "Creating (multi-dataset) encoder...\n",
      "Encoding datasets...\n",
      "Getting train/test raw datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ad3e4650f1415aa894dc2a01514a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c77819205549b4888332c08b930721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90f76f4ad014123b445cdbc5aa1db58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b523a578a6f9453ba39328a12b288da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab4464328a149829aa66491d3e088b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e9e57daabf4c72824fa66eaf383af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aadf9a652484dc38118db616d57c2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7cb8e4cc37457b857045fea2c5d134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fae8ff348c1406eba767c391d10a90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cbb8e87c1541a2a54d9cbddfb309ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format:  25%|██▌       | 1/4 [00:18<00:54, 18.29s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a071738a614e3d90ac7a546812da25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7327f8c36a5e4f6384e8cd976f0e78c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format:  50%|█████     | 2/4 [00:37<00:37, 18.80s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8832819b03da4178bcb7e3a9385c0f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0eb774efca4114baf846b896453d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format:  75%|███████▌  | 3/4 [00:56<00:18, 18.73s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca150320d02047899abb4d612cc0f1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6998c517699b491dbcf35ec0f712b3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format: 100%|██████████| 4/4 [01:16<00:00, 19.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdaac2ec71c947bdb14316b72fad4710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d0d99aa30849e9a3bd9879b5315b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length train: 160, min length train: 160\n",
      "max length test: 160, min length test: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5d6604955d475d8c04d8daf7cf5a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d6981b274d417f8ab02601b14590be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...:  25%|██▌       | 1/4 [00:37<01:53, 37.81s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b566e96fcc8e4047b1aa383f45913152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a00b09a2f84ac28549e83686a4e212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length train: 160, min length train: 160\n",
      "max length test: 160, min length test: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a595651da89e4216892660ecdba171ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab47ba01f21f4284b65dc4bf08bcccf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...:  50%|█████     | 2/4 [01:17<01:17, 38.72s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9451821a354b5382a35a989bbde6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416ff531c4ff4ca99a10fb63a0df02d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length train: 160, min length train: 160\n",
      "max length test: 160, min length test: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475dc85362514e338b74be151a4ab5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beca918a2073403896776219502d0ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...:  75%|███████▌  | 3/4 [01:56<00:38, 38.95s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcaecb5752242178639bb405f659662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53b58ddfe0c44229fc59bb420e5fda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length train: 160, min length train: 160\n",
      "max length test: 160, min length test: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98989518634441eebdf2c0317487c947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950227e4ad7042938d28cb6c33f2c689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...: 100%|██████████| 4/4 [02:33<00:00, 38.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing dataset(s) information for debugging purposes...\n",
      "Dataset: reasoning\n",
      "Dataset({\n",
      "    features: ['question', 'reference_answer', 'responses', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 108\n",
      "})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dataset: awesome\n",
      "Dataset({\n",
      "    features: ['act', 'prompt', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 106\n",
      "})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dataset: gsm8k\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 108\n",
      "})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dataset: leetcode\n",
      "Dataset({\n",
      "    features: ['id', 'slug', 'title', 'difficulty', 'content', 'java', 'c++', 'python', 'javascript', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 47\n",
      "})\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FC8536B9-226D-421B-8232-9E2BA4D7E96C\n",
    "\n",
    "Create some datasets to test generalization of the steering.\n",
    "\n",
    "Implement steering on (1) the test-set (which is small) and (2) some manual examples unrelated to the actual\n",
    "sorts of questions we used... remember the template in `generate_prompt_variations_dataset`, we will instead ask some semi-arbitrary questions...\n",
    "also (3) load a generic dataset (i.e. from HF) and see if we can just make those responses longer (use the following hf dataset: )\n",
    "\n",
    "We put ALL of these into a dictionry of datasets. The custom-written questions (things I kind of would do myself)\n",
    "are in the \"custom\" dataset, the huggingface ones are pretty clear here, and the \"test_set\" one is the test set.\n",
    "\"\"\"\n",
    "print(\"Creating rawwww HF datasets...\")\n",
    "datasets_hf = {\n",
    "    \"reasoning\": load_dataset(\"facebook/natural_reasoning\", split=\"train\").shuffle(seed=42).select(range(120)),\n",
    "    \"awesome\": load_dataset(\"fka/awesome-chatgpt-prompts\", split=\"train\").shuffle(seed=42).select(range(120)),\n",
    "    \"gsm8k\": load_dataset(\"openai/gsm8k\", \"main\", split=\"train\").shuffle(seed=42).select(range(120)),\n",
    "    \"leetcode\": load_dataset(\"greengerong/leetcode\", split=\"train\").shuffle(seed=42).select(range(120)),\n",
    "}\n",
    "print(\"Creating unique encoding args...\")\n",
    "multi_encoding_args = EncodingArgs(\n",
    "    # We WILL be doing full generation so let's be willing to go up to a reasonable length... I think llama was trained on\n",
    "    # up to 8K or so tokens\n",
    "    llm_tok_max_length=3000,\n",
    "    llm_tok_max_prompt_length=1000,\n",
    "    test_size_pct=0.1, # unfortunately, we will be just not using  the \"test\" set since ALL this is for testing LOL\n",
    "    message_key={\n",
    "        \"reasoning\": \"question\",\n",
    "        \"awesome\": \"prompt\",\n",
    "        \"gsm8k\": \"question\",\n",
    "        \"leetcode\": \"content\",\n",
    "    },\n",
    "    # NOTE the usage of a new system prompt!\n",
    "    # TODO(Adrianoh) allow for the creation of multiple different system prompts in this system\n",
    "    system_prompt=\"\"\"You are a helpful assistant tasked with helping users with a variety of tasks they may need help with, including, but not limited to:\n",
    "    - Programming (i.e. you may recieve code or problem descriptions and you'll need to solve them)\n",
    "    - Reasoning and mathematical problems (i.e. word problems, real world situations, etc...)\n",
    "    - Technical, engineering, and scientific knowledge and problem solving\n",
    "    - Business, legal, and financial knowledge and best-practices and planning\n",
    "    - Information about documentation or other textual sources users may give you\n",
    "    - General knowledge and trivia\n",
    "    ...\n",
    "\n",
    "    Make sure to be helpful, concise, and professional.\n",
    "    \"\"\",\n",
    ")\n",
    "print(\"Creating (multi-dataset) encoder...\")\n",
    "multi_dataset_encoder = DatasetEncoder(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    datasets=datasets_hf,\n",
    "    encoding_args=multi_encoding_args,\n",
    ")\n",
    "print(\"Encoding datasets...\")\n",
    "tokenized_datasets = multi_dataset_encoder.get_trainable_datasets()\n",
    "assert set(tokenized_datasets.keys()) == set(datasets_hf.keys())\n",
    "datasets = {\n",
    "    # Ignore this terminology, there is no training happening\n",
    "    k: trainset_as_testset for k, (trainset_as_testset, _) in tokenized_datasets.items()\n",
    "}\n",
    "assert \"test_set\" not in datasets\n",
    "datasets[\"test_set\"] = dataset_test\n",
    "assert all(isinstance(v, Dataset) for v in datasets.values())\n",
    "print(\"Printing dataset(s) information for debugging purposes...\")\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    print(dataset)\n",
    "    print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom dataset length is  6\n",
      "Custom dataet original examples:\n",
      "{'custom': Dataset({\n",
      "    features: ['prompt'],\n",
      "    num_rows: 6\n",
      "})}\n",
      "====================================================================================================\n",
      "Creating encoder...\n",
      "Encoding custom dataset...\n",
      "Getting train/test raw datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/align3_drive/adrianoh/miniconda3/envs/ifyoudont/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <class '__main__.EncodingArgs'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/mnt/align3_drive/adrianoh/miniconda3/envs/ifyoudont/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <class '__main__.EncodingArgs'>: __main__.EncodingArgs has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e81fe4c4ac94759bfdd6a7d0b19617f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feba40664b2d4a9e8f0821a484c0ad47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaec53735b3342e0897631cfe38cfa19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6e303c145b499f95c418db1b7b7b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting datasets to be in conversation format: 100%|██████████| 1/1 [00:17<00:00, 18.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d098e0f292ec461794f044a396107c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44b12f5363e4be6ad3042aadd40a66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length train: 39, min length train: 39\n",
      "max length test: 39, min length test: 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6994b1f124441ba74a0fdd2c164204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02e530a33b34de7b37b9ee9a9aa47f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template and tokenizing datasets...: 100%|██████████| 1/1 [00:40<00:00, 40.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] ===========================\n",
      "Custom dataset length is  6\n",
      "{'custom': Dataset({\n",
      "    features: ['prompt'],\n",
      "    num_rows: 6\n",
      "})}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "slice(None, 10, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/align4_drive2/adrianoh/git2/MiscInterpExperiments/length-2025-02-11/steering_experiments.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balign-3.csail.mit.edu/mnt/align4_drive2/adrianoh/git2/MiscInterpExperiments/length-2025-02-11/steering_experiments.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCustom dataset length is \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(custom_test)) \u001b[39m# you should ensure it is like above\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balign-3.csail.mit.edu/mnt/align4_drive2/adrianoh/git2/MiscInterpExperiments/length-2025-02-11/steering_experiments.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mprint\u001b[39m(custom_dataset)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Balign-3.csail.mit.edu/mnt/align4_drive2/adrianoh/git2/MiscInterpExperiments/length-2025-02-11/steering_experiments.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mprint\u001b[39m(custom_dataset[:\u001b[39m10\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balign-3.csail.mit.edu/mnt/align4_drive2/adrianoh/git2/MiscInterpExperiments/length-2025-02-11/steering_experiments.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# datasets[\"custom\"] = custom_train\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: slice(None, 10, None)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "36E3257E-4704-4549-B2AD-2DE6F2D5E7E4\n",
    "\"\"\"\n",
    "custom_dataset = {\n",
    "    \"custom\": Dataset.from_list([\n",
    "        {\n",
    "            \"prompt\": \"Can you explain how KL divergence is different from the cross-entropy loss? Can you try to explain the units in terms bits over channels?\",\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"\"\"what are some books that have the following concepts well-covered?\n",
    "            ```\n",
    "            Introduction to Bayesian inference; motivations from de Finetti, decision theory, etc.\n",
    "            Hierarchical modeling, including popular models such as latent Dirichlet allocation\n",
    "            Approximate posterior inference\n",
    "            Variational inference, mean-field, stochastic variational inference, challenges/limitations of VI, etc.\n",
    "            Monte Carlo, avoiding random-walk behavior, Hamiltonian Monte Carlo/NUTS/Stan, etc.\n",
    "            Evaluation, sensitivity, robustness\n",
    "            Bayesian nonparametrics: why and how\n",
    "            Mixture models, admixtures, Dirichlet process, Chinese restaurant process\n",
    "            Learning functions, Gaussian processes\n",
    "            Probabilistic numerics\n",
    "            Bayesian optimization\n",
    "            ```\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"In jaxtyping, does Float lead to runtime errors if the parameter does not have the right type?\",\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"how can I tell if a folder is a symlink on teh commandline\",\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"What is the capital of Yugoslavia? Does yugoslavia even exist?\",\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Write h33l0 in l34tsp34k BUT also in morse code (i.e. encode h then 3 then 3 etc...) ty bby. Then, write me a short poem in l34tsp34k AND m0rs3 c0d3.\",\n",
    "        },\n",
    "    ])\n",
    "}\n",
    "print(\"Custom dataset length is \", len(custom_dataset[\"custom\"]))\n",
    "print(\"Custom dataet original examples:\")\n",
    "print(custom_dataset)\n",
    "print(\"=\"*100)\n",
    "print(\"Creating encoder...\")\n",
    "custom_encoder = DatasetEncoder(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    datasets=custom_dataset,\n",
    "    encoding_args=EncodingArgs(\n",
    "        llm_tok_max_length=3000,\n",
    "        llm_tok_max_prompt_length=1000,\n",
    "        test_size_pct=0.5, # so it won't break, but we will merge later\n",
    "        message_key={\n",
    "            \"custom\": \"prompt\",\n",
    "        },\n",
    "        # NOTE: another system prompt! and it is diferent from both above, this should get us a better\n",
    "        # tap on generalization (note all of them started with \"You are a helpful assistant\" and this one does not).\n",
    "        system_prompt=\"\"\"Be concise and precise, but make sure to explain things clearly.\"\"\"\n",
    "    ),\n",
    ")\n",
    "print(\"Encoding custom dataset...\")\n",
    "_ = custom_encoder.get_trainable_datasets()\n",
    "print(\"[OK] ===========================\")\n",
    "custom_test = concatenate_datasets(list(_[\"custom\"])) # Merge the datasets via concatenation\n",
    "print(\"Custom dataset length is \", len(custom_test)) # you should ensure it is like above\n",
    "print(custom_test)\n",
    "print(custom_test[:3])\n",
    "datasets[\"custom\"] = custom_test\n",
    "print(\"=\"*100)\n",
    "print(\"All datasets for testing are now...\")\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets_shorter\n",
      "Total number of items: 30\n",
      "{'reasoning': Dataset({\n",
      "    features: ['question', 'reference_answer', 'responses', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 5\n",
      "}), 'awesome': Dataset({\n",
      "    features: ['act', 'prompt', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 5\n",
      "}), 'gsm8k': Dataset({\n",
      "    features: ['question', 'answer', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 5\n",
      "}), 'leetcode': Dataset({\n",
      "    features: ['id', 'slug', 'title', 'difficulty', 'content', 'java', 'c++', 'python', 'javascript', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 5\n",
      "}), 'test_set': Dataset({\n",
      "    features: ['length', 'topic', 'prompt', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 5\n",
      "}), 'custom': Dataset({\n",
      "    features: ['prompt', 'conversation', 'input_ids', 'input_templated'],\n",
      "    num_rows: 5\n",
      "})}\n",
      "====================================================================================================\n",
      "Do nothing module\n",
      "Linear(in_features=2048, out_features=2048, bias=True)\n",
      "Real steering module\n",
      "Linear(in_features=2048, out_features=2048, bias=True)\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating vanilla generations:   0%|          | 0/6 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  17%|█▋        | 1/6 [02:43<13:35, 163.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  33%|███▎      | 2/6 [05:11<10:18, 154.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  50%|█████     | 3/6 [08:16<08:24, 168.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  67%|██████▋   | 4/6 [09:34<04:25, 132.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  83%|████████▎ | 5/6 [11:35<02:08, 128.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations: 100%|██████████| 6/6 [11:38<00:00, 116.47s/it]\n",
      "Generating vanilla generations:   0%|          | 0/6 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  17%|█▋        | 1/6 [05:46<28:53, 346.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  33%|███▎      | 2/6 [11:39<23:20, 350.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  50%|█████     | 3/6 [17:33<17:35, 351.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  67%|██████▋   | 4/6 [20:39<09:33, 286.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations:  83%|████████▎ | 5/6 [23:10<03:57, 237.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating vanilla generations: 100%|██████████| 6/6 [23:30<00:00, 235.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generation complete for all datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "B7D4CE13-799E-424D-BF70-EE6E9529EB47\n",
    "\n",
    "Generate original + hooked responses. NOTE: you should be able to batch this shit (across datasets) but we don't\n",
    "because... welp... eh. Also... we don't batch AT ALL because for hooking it's harder to control the\n",
    "place we insert, so we just do inference WITHOUT performing any particular batching strategy... ehh\n",
    "(I will need to deal with this later... but it would have been a pain to generate the vector directions\n",
    "otherwise).\n",
    "\n",
    "I guess one last thing is we apply the steering vector EVERYWHERE lol. This makes it a little easier to do (and we\n",
    "make all datasets less than 20 elements because it's faster and no-batch is slow AF.\n",
    "\n",
    "PS: we trained the diff vector when there was batching so... YOLO hope for the best I guess. Hope I had no bugs,\n",
    "kinda seems to work. I wish I had a day extra to write some unit tests n shit.\n",
    "\"\"\"\n",
    "# print(datasets)\n",
    "datasets_shorter = deepcopy(datasets)\n",
    "datasets_shorter = {\n",
    "    # Make this really short so we aren't waiting too long :/\n",
    "    ds_name: ds.select(range(min(5, len(ds)))) for ds_name, ds in datasets_shorter.items() # fmt: skip\n",
    "}\n",
    "print(\"datasets_shorter\")\n",
    "total_num_items = sum(len(v) for v in datasets_shorter.values())\n",
    "print(f\"Total number of items: {total_num_items}\")\n",
    "print(datasets_shorter)\n",
    "print(\"=\"*100)\n",
    "assert all(len(v) <= 5 for v in datasets_shorter.values())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# For some reason I was using a lot of memory and I'm not sure why...\n",
    "# print(torch.cuda.memory_summary(abbreviated=True))\n",
    "# for obj in gc.get_objects():\n",
    "#     try:\n",
    "#         if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#             print(type(obj), obj.size(), obj.dtype, obj.device, obj.memory_allocated())\n",
    "#     except:\n",
    "#         pass\n",
    "# Generate responses for each dataset\n",
    "# NOTE: the prompt is included in the generation so we are just storing the output\n",
    "dataset_name2all_vanilla_generations: Dict[str, List[str]] = {}\n",
    "dataset_name2all_steered_l15_generations: Dict[str, List[str]] = {}\n",
    "do_nothing_module = steering_vec2steering_module(steering_vec=torch.zeros(model_hidden_size), device=model.device)\n",
    "layer_idx = 8\n",
    "# Scale it up for more impact lol\n",
    "last_token_last_layer_steering_vec = steering_vecs[layer_idx+1, -1, :]*15 # shape torch.Size([17, 85, 2048]) select the last token one\n",
    "assert last_token_last_layer_steering_vec.shape == (model_hidden_size,)\n",
    "real_filter_module = steering_vec2steering_module(steering_vec=last_token_last_layer_steering_vec, device=model.device)\n",
    "print(\"Do nothing module\")\n",
    "print(do_nothing_module)\n",
    "print(\"Real steering module\")\n",
    "print(real_filter_module)\n",
    "print(\"=\"*100)\n",
    "# NOTE: this corresponds to \"17th\" = idx 16, since 0th => embeddings and then layer index 0 -> layer 1 ->  idx 1 and then go 15 up from 1\n",
    "# of the function... which includes the input)\n",
    "max_output_tokens = 2000 # 3000 - 1000 :/\n",
    "ddecoder = DatasetDecoder(model=model, tokenizer=tokenizer, device=model.device)\n",
    "for this_hook_module, name2all_dict in zip(\n",
    "    [do_nothing_module, real_filter_module],\n",
    "    [dataset_name2all_vanilla_generations, dataset_name2all_steered_l15_generations]\n",
    "):\n",
    "    for dataset_name, dataset in tqdm.tqdm(datasets.items(), desc=\"Generating vanilla generations\", total=len(datasets_shorter)): \n",
    "        with contextlib.redirect_stdout(io.StringIO()): # Avoid my own logspam LOL\n",
    "            with contextlib.redirect_stderr(io.StringIO()): # Avoid warning logspam... appears not to work though ngl :/\n",
    "                with named_forward_hooks(model, {\n",
    "                    # Feed into the next layer cuz we are doing pre-hooks\n",
    "                    f\"model.layers.{layer_idx+1}\": ( # Just kind of an arbitrary layer for testing, didn't get time to test more than like 2-3\n",
    "                        lambda hooks_object, name, module, inp, out: filter_hook_fn(this_hook_module, hooks_object, name, module, inp, out),\n",
    "                        # Pre-hook: before module takes it in (otherwise it is after)...\n",
    "                        # NOTE: that pre-hook is the right way to do it if we want to optimize AFAIK\n",
    "                        True\n",
    "                    )\n",
    "                }):\n",
    "                    generations = ddecoder.batch_decode(\n",
    "                        model=model,\n",
    "                        tokenizer=tokenizer,\n",
    "                        questions=dataset,\n",
    "                        batch_size=1, # NOTE this is as we said above\n",
    "                        # DEFAULTS OK HERE (close to greedy but not exactly so we get a little variety)\n",
    "                        generation_kwargs={ \"do_sample\": True,\"temperature\": 1,\"top_k\": 50,\"top_p\": 0.95,\"max_new_tokens\": max_output_tokens },\n",
    "                        device=model.device,\n",
    "                        optimize_batch_size=False,\n",
    "                        return_input_ids_pt=False,\n",
    "                        return_optimal_batch_size=False,\n",
    "                        return_activations=False,\n",
    "                        debug=False # this is helpful for debugging\n",
    "                    )\n",
    "                    name2all_dict[dataset_name] = generations\n",
    "                # print(f\"Completed generating {len(generations)} responses for {dataset_name}\") # Logspam\n",
    "                pass\n",
    "assert len(dataset_name2all_vanilla_generations) == len(dataset_name2all_steered_l15_generations) # fmt: skip\n",
    "assert all(len(dataset_name2all_vanilla_generations[k].generations) == len(dataset_name2all_steered_l15_generations[k].generations) for k in dataset_name2all_vanilla_generations) # fmt: skip\n",
    "print(\"[OK] Generation complete for all datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "STORING GENERATIONS FOR vanilla\n",
      "[OK] Saved generations to output_steering_experiments/vanilla/generations.json\n",
      "Saving individual generations...\n",
      "[OK] Saved generations to output_steering_experiments/vanilla/reasoning_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/vanilla/awesome_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/vanilla/gsm8k_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/vanilla/leetcode_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/vanilla/test_set_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/vanilla/custom_generations.json\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "STORING GENERATIONS FOR steered_layer_idx_8\n",
      "[OK] Saved generations to output_steering_experiments/steered_layer_idx_8/generations.json\n",
      "Saving individual generations...\n",
      "[OK] Saved generations to output_steering_experiments/steered_layer_idx_8/reasoning_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/steered_layer_idx_8/awesome_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/steered_layer_idx_8/gsm8k_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/steered_layer_idx_8/leetcode_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/steered_layer_idx_8/test_set_generations.json\n",
      "[OK] Saved generations to output_steering_experiments/steered_layer_idx_8/custom_generations.json\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5A142998-9320-496F-B8B9-21AC55803977\n",
    "\n",
    "Save things to files and then we will inspect and work with them later.\n",
    "\"\"\"\n",
    "class Generations(pydantic.BaseModel):\n",
    "    dataset_name: str\n",
    "    generations: List[str]\n",
    "class AllGenerations(pydantic.BaseModel):\n",
    "    generations: List[Generations]\n",
    "\n",
    "for name2all, all_name2all in [\n",
    "    (dataset_name2all_vanilla_generations, \"vanilla\"),\n",
    "    (dataset_name2all_steered_l15_generations, f\"steered_layer_idx_{layer_idx}\"),\n",
    "]:\n",
    "    print(\"=\"*100)\n",
    "    print(\"STORING GENERATIONS FOR\", all_name2all)\n",
    "    assert all(isinstance(name2all[k], BatchEncodedOutput) for k in name2all), f\"Generations must be BatchEncodedOutput, but {name2all} is not\" # fmt: skip\n",
    "    assert all(all(isinstance(v, str) for v in name2all[k].generations) for k in name2all), \"Generations must be lists of strings\" # fmt: skip\n",
    "    all_generations = AllGenerations(\n",
    "        generations=[\n",
    "            Generations(dataset_name=k, generations=v.generations)\n",
    "            for k, v in name2all.items()\n",
    "        ]\n",
    "    )\n",
    "    assert isinstance(all_name2all, str)\n",
    "    output_path_full = output_dir / all_name2all/ f\"generations.json\"\n",
    "    if not output_path_full.parent.exists():\n",
    "        output_path_full.parent.mkdir(parents=True, exist_ok=False)\n",
    "    if not output_path_full.exists():\n",
    "        assert not output_path_full.exists(), f\"output_path_full={output_path_full} already exists\"\n",
    "        with open(output_path_full, \"w\") as f:\n",
    "            f.write(all_generations.model_dump_json(indent=4))\n",
    "        print(f\"[OK] Saved generations to {output_path_full}\")\n",
    "    print(\"Saving individual generations...\") # Can make it easier to read\n",
    "    for generations_obj in all_generations.generations:\n",
    "        dataset_name = generations_obj.dataset_name\n",
    "        generations = generations_obj.generations\n",
    "        assert isinstance(generations, list) and all(isinstance(v, str) for v in generations), f\"Generations must be a list of strings, but {generations} is not\" # fmt: skip\n",
    "        output_path = output_dir / all_name2all / f\"{dataset_name}_generations.json\"\n",
    "        if not output_path.parent.exists():\n",
    "            output_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "        if not output_path.exists():    \n",
    "            assert not output_path.exists(), f\"output_path={output_path} already exists\"\n",
    "            with open(output_path, \"w\") as f:\n",
    "                f.write(generations_obj.model_dump_json(indent=4))\n",
    "            print(f\"[OK] Saved generations to {output_path}\")\n",
    "    print(\"=\"*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: reasoning\n",
      "Vanilla - Mean: 1293.24, Min: 795, Max: 3222, Std: 514.02, StdErr: 49.46\n",
      "Steered - Mean: 1971.29, Min: 822, Max: 5365, Std: 818.88, StdErr: 78.80\n",
      "Difference (Steered - Vanilla): 678.05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: awesome\n",
      "Vanilla - Mean: 1258.02, Min: 822, Max: 2775, Std: 428.69, StdErr: 41.64\n",
      "Steered - Mean: 2031.47, Min: 835, Max: 5583, Std: 846.49, StdErr: 82.22\n",
      "Difference (Steered - Vanilla): 773.45\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: gsm8k\n",
      "Vanilla - Mean: 1360.06, Min: 795, Max: 3191, Std: 588.36, StdErr: 56.61\n",
      "Steered - Mean: 2030.29, Min: 822, Max: 5543, Std: 844.13, StdErr: 81.23\n",
      "Difference (Steered - Vanilla): 670.23\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: leetcode\n",
      "Vanilla - Mean: 1345.17, Min: 795, Max: 2862, Std: 518.98, StdErr: 75.70\n",
      "Steered - Mean: 2312.81, Min: 1002, Max: 5002, Std: 991.33, StdErr: 144.60\n",
      "Difference (Steered - Vanilla): 967.64\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: test_set\n",
      "Vanilla - Mean: 2712.33, Min: 1068, Max: 6639, Std: 1718.99, StdErr: 375.11\n",
      "Steered - Mean: 3397.24, Min: 1022, Max: 11794, Std: 2780.85, StdErr: 606.83\n",
      "Difference (Steered - Vanilla): 684.90\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: custom\n",
      "Vanilla - Mean: 312.17, Min: 270, Max: 386, Std: 39.82, StdErr: 16.26\n",
      "Steered - Mean: 1584.83, Min: 280, Max: 3414, Std: 1279.79, StdErr: 522.47\n",
      "Difference (Steered - Vanilla): 1272.67\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "8B04545E-B159-4A65-AE77-D474D853FE2E\n",
    "\n",
    "We simply look at the length statistics of both the generations:\n",
    "\"\"\"\n",
    "# class Prober:\n",
    "#     \"\"\"\n",
    "#     A class to probe the model for steering. It is also basically a static-like class, but stateful\n",
    "#     (which helps) since it does a bunch of different probes in sequence/parallel (basically the goal\n",
    "#     with this is to get a probe of the activations at every single layer of the model so we need to\n",
    "#     run the same thing like a gazillion times and it helps to abstract this).\n",
    "#     \"\"\"\n",
    "#     def __init__(self, activations_dataset: Dataset, generations_dataset: Dataset) -> None:\n",
    "#         self.activations_dataset = activations_dataset\n",
    "#         self.generations_dataset = generations_dataset\n",
    "#         raise NotImplementedError\n",
    "\n",
    "#     def probe(self) -> Tuple[float, float]:\n",
    "#         raise NotImplementedError\n",
    "\n",
    "lengths_vanilla = {dname: np.array([len(v) for v in dataset_name2all_vanilla_generations[dname].generations]) for dname in dataset_name2all_vanilla_generations}\n",
    "lengths_steered = {dname: np.array([len(v) for v in dataset_name2all_steered_l15_generations[dname].generations]) for dname in dataset_name2all_steered_l15_generations}\n",
    "assert set(lengths_vanilla.keys()) == set(lengths_steered.keys())\n",
    "for dname in lengths_vanilla:\n",
    "    lengths_vanilla[dname] = np.array(lengths_vanilla[dname])\n",
    "    vanilla_mean, vanilla_min, vanilla_max, vanilla_std, vanilla_stderr = np.mean(lengths_vanilla[dname]), np.min(lengths_vanilla[dname]), np.max(lengths_vanilla[dname]), np.std(lengths_vanilla[dname]), np.std(lengths_vanilla[dname]) / np.sqrt(len(lengths_vanilla[dname]))\n",
    "    lengths_steered[dname] = np.array(lengths_steered[dname])\n",
    "    steered_mean, steered_min, steered_max, steered_std, steered_stderr = np.mean(lengths_steered[dname]), np.min(lengths_steered[dname]), np.max(lengths_steered[dname]), np.std(lengths_steered[dname]), np.std(lengths_steered[dname]) / np.sqrt(len(lengths_steered[dname]))\n",
    "    # Create a histogram plot for comparing vanilla and steered lengths\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths_vanilla[dname], bins=20, alpha=0.5, color='blue', label='Vanilla')\n",
    "    plt.hist(lengths_steered[dname], bins=20, alpha=0.5, color='red', label='Steered')\n",
    "    plt.title(f\"Length Comparison: {dname}\")\n",
    "    plt.xlabel(\"Length\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print out the statistics\n",
    "    print(f\"Dataset: {dname}\")\n",
    "    print(f\"Vanilla - Mean: {vanilla_mean:.2f}, Min: {vanilla_min}, Max: {vanilla_max}, Std: {vanilla_std:.2f}, StdErr: {vanilla_stderr:.2f}\")\n",
    "    print(f\"Steered - Mean: {steered_mean:.2f}, Min: {steered_min}, Max: {steered_max}, Std: {steered_std:.2f}, StdErr: {steered_stderr:.2f}\")\n",
    "    print(f\"Difference (Steered - Vanilla): {steered_mean - vanilla_mean:.2f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifyoudont",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
